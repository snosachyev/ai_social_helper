# ğŸš€ Quick Start Guide: 1000+ Users RAG System

## ğŸ“‹ Overview

This guide provides step-by-step instructions to deploy and test the RAG system optimized for 1000+ concurrent users using high-performance Go API Gateway.

## ğŸ¯ What You'll Get

- âœ… **5 Go API Gateway instances** with concurrent processing
- âœ… **Nginx load balancer** with optimized settings
- âœ… **Redis caching** for high-performance data access
- âœ… **PostgreSQL database** with optimized configuration
- âœ… **Load testing scripts** for performance validation
- âœ… **Monitoring and metrics** for system health

## ğŸ› ï¸ Prerequisites

### System Requirements
- **CPU**: 8+ cores recommended
- **Memory**: 16GB+ RAM recommended
- **Storage**: 50GB+ free space
- **Docker**: Latest version installed
- **Docker Compose**: v2.0+ recommended

### Software Required
```bash
# Install Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh

# Install k6 for load testing
sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
echo "deb https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
sudo apt-get update
sudo apt-get install k6
```

## ğŸš€ Deployment Steps

### Step 1: Clone and Prepare
```bash
# Navigate to project directory
cd /home/sergey/projects/ai_coding/ai_social_helper

# Make scripts executable
chmod +x scripts/start_high_perf.sh
```

### Step 2: Start High-Performance System
```bash
# Launch the optimized system
./scripts/start_high_perf.sh
```

**Expected Output:**
```
ğŸš€ Starting High-Performance RAG System for 1000+ Users
======================================================
âš¡ 5x Go API Gateways + Nginx + Redis + PostgreSQL

âœ… High-Performance system is ready!
ğŸŒ Access Points:
   Load Balancer: http://localhost:80
   Health: http://localhost:80/health
   Metrics: http://localhost:80/metrics
```

### Step 3: Verify Deployment
```bash
# Check system health
curl http://localhost:80/health

# Expected response:
{"service_name":"api-gateway-go","status":"healthy",...}

# Check metrics
curl http://localhost:80/metrics

# Test API functionality
curl -X POST http://localhost:80/query \
  -H "Content-Type: application/json" \
  -d '{"query":"What is Go performance?", "top_k":5}'
```

## ğŸ§ª Performance Testing

### Test 1: Basic Functionality (100 Users)
```bash
k6 run --vus 100 --duration 30s tests/performance/k6/high_perf_test.js
```

### Test 2: Medium Load (500 Users)
```bash
k6 run --vus 500 --duration 60s tests/performance/k6/high_perf_test.js
```

### Test 3: High Load (1000 Users)
```bash
k6 run --vus 1000 --duration 60s tests/performance/k6/high_perf_test.js
```

### Test 4: Stress Test (2000 Users)
```bash
k6 run --vus 2000 --duration 60s tests/performance/k6/high_perf_test.js
```

## ğŸ“Š Expected Performance Metrics

| Users | Response Time (P95) | Error Rate | Throughput |
|-------|-------------------|------------|------------|
| 100   | <50ms             | <1%        | 500 RPS    |
| 500   | <100ms            | <3%        | 1000 RPS   |
| 1000  | <200ms            | <5%        | 2000 RPS   |
| 2000  | <300ms            | <10%       | 3000 RPS   |

## ğŸ” Monitoring

### System Health Check
```bash
# Check all containers
docker compose -f docker-compose.high-perf.yml ps

# View logs
docker compose -f docker-compose.high-perf.yml logs -f

# Check resource usage
docker stats
```

### API Endpoints
```bash
# Health check
curl http://localhost:80/health

# System metrics
curl http://localhost:80/metrics

# Test query
curl -X POST http://localhost:80/query \
  -H "Content-Type: application/json" \
  -d '{"query":"test query", "top_k":5}'

# List documents
curl http://localhost:80/documents

# Get models
curl http://localhost:80/models
```

## ğŸ› ï¸ Configuration

### Nginx Load Balancer
- **Worker Connections**: 8192
- **Rate Limiting**: 500 req/s per IP
- **Connection Pooling**: 128 connections
- **Buffer Sizes**: Optimized for high load

### Go API Gateway
- **Instances**: 5 containers
- **Memory**: 1GB per instance
- **CPU**: 2 cores per instance
- **Caching**: 5-minute in-memory cache

### Database Configuration
- **PostgreSQL**: 4GB memory, 2 cores
- **Redis**: 2GB memory, connection pooling
- **Connection Limits**: Optimized for concurrency

## ğŸ”§ Troubleshooting

### Common Issues

#### 1. High Error Rates
```bash
# Check container logs
docker compose -f docker-compose.high-perf.yml logs api-gateway-go-1

# Check resource usage
docker stats

# Restart services
docker compose -f docker-compose.high-perf.yml restart
```

#### 2. Slow Response Times
```bash
# Check Nginx configuration
docker exec rag-nginx-hp nginx -t

# Monitor database connections
docker exec rag-postgres-hp psql -U rag_user -d rag_db -c "SELECT count(*) FROM pg_stat_activity;"

# Clear Redis cache
docker exec rag-redis-hp redis-cli FLUSHALL
```

#### 3. Connection Refused
```bash
# Check if all services are running
docker compose -f docker-compose.high-perf.yml ps

# Verify network connectivity
docker network ls
docker network inspect ai_social_helper_rag-network
```

## ğŸ“ˆ Scaling Guidelines

### Horizontal Scaling
```bash
# Add more Go instances (edit docker-compose.high-perf.yml)
# Copy api-gateway-go-5 section and increment numbers

# Update Nginx upstream configuration
# Add new servers to upstream block in nginx_hp.conf

# Restart with new configuration
docker compose -f docker-compose.high-perf.yml up -d --scale api-gateway-go=8
```

### Vertical Scaling
```bash
# Increase resource limits in docker-compose.high-perf.yml
deploy:
  resources:
    limits:
      memory: 4G  # Increase from 2G
      cpus: '4.0' # Increase from '2.0'
```

## ğŸ¯ Production Deployment

### Environment Variables
```bash
# Create .env file
cat > .env << EOF
POSTGRES_DB=rag_db
POSTGRES_USER=rag_user
POSTGRES_PASSWORD=your_secure_password
REDIS_PASSWORD=your_redis_password
EOF
```

### Security Considerations
```bash
# Use HTTPS in production
# Configure SSL certificates
# Set up firewall rules
# Enable authentication
# Monitor access logs
```

### Backup Strategy
```bash
# Database backup
docker exec rag-postgres-hp pg_dump -U rag_user rag_db > backup.sql

# Redis backup
docker exec rag-redis-hp redis-cli BGSAVE
```

## ğŸ“š Additional Resources

### Documentation
- [Full Optimization Report](FINAL_1000_USERS_OPTIMIZATION_REPORT.md)
- [Architecture Guide](ARCHITECTURE.md)
- [API Documentation](docs/api/API_REFERENCE.md)

### Scripts and Tools
- `scripts/start_high_perf.sh` - Start high-performance system
- `tests/performance/k6/high_perf_test.js` - Load testing script
- `infrastructure/nginx/nginx_hp.conf` - Nginx configuration

### Support
- Check logs for error details
- Monitor system resources
- Review performance metrics
- Scale resources as needed

## ğŸ† Success Criteria

Your system is successfully optimized for 1000+ users if:

âœ… **Health Check**: All containers running and healthy  
âœ… **API Response**: <200ms P95 response time  
âœ… **Error Rate**: <5% under 1000 concurrent users  
âœ… **Throughput**: 2000+ requests per second  
âœ… **Stability**: System remains responsive under load  

## ğŸ‰ Next Steps

1. **Monitor Performance**: Set up continuous monitoring
2. **Load Test**: Regular performance validation
3. **Scale Resources**: Adjust based on usage patterns
4. **Optimize Further**: Fine-tune based on real-world usage
5. **Plan Migration**: Consider Kubernetes for cloud deployment

---

**ğŸš€ Your RAG system is now ready for 1000+ users!**

For questions or issues, refer to the [Full Optimization Report](FINAL_1000_USERS_OPTIMIZATION_REPORT.md) or check the system logs.
