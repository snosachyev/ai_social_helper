name: Test Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

env:
  PYTHON_VERSION: "3.9"
  NODE_VERSION: "18"

jobs:
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r tests/requirements-test.txt
    
    - name: Run unit tests
      run: |
        pytest tests/unit/ -v \
          --cov=src \
          --cov=services \
          --cov-report=xml \
          --cov-report=html \
          --cov-fail-under=90
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
    
    - name: Archive coverage reports
      uses: actions/upload-artifact@v3
      with:
        name: coverage-reports
        path: htmlcov/

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test
          POSTGRES_USER: test
          POSTGRES_DB: test_rag
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
      
      clickhouse:
        image: clickhouse/clickhouse-server:latest
        options: >-
          --health-cmd "clickhouse-client --query 'SELECT 1'"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 8123:8123
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r tests/requirements-test.txt
    
    - name: Wait for services
      run: |
        sleep 10
        python -c "
import psycopg2
import redis
import time
import os

# Wait for PostgreSQL
for i in range(30):
    try:
        conn = psycopg2.connect(
            host='localhost',
            port=5432,
            user='test',
            password='test',
            database='test_rag'
        )
        conn.close()
        break
    except:
        time.sleep(1)

# Wait for Redis
for i in range(30):
    try:
        r = redis.Redis(host='localhost', port=6379)
        r.ping()
        break
    except:
        time.sleep(1)
        "
    
    - name: Run integration tests
      env:
        DATABASE_URL: postgresql://test:test@localhost:5432/test_rag
        REDIS_URL: redis://localhost:6379
        CLICKHOUSE_URL: clickhouse://localhost:8123/default
      run: |
        pytest tests/integration/ -v \
          --timeout=300 \
          --maxfail=5
    
    - name: Archive integration test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: integration-test-results
        path: |
          tests/integration/reports/
          **/test-results.xml

  contract-tests:
    name: Contract Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r tests/requirements-test.txt
    
    - name: Start services for contract testing
      run: |
        docker-compose -f docker-compose.test.yml up -d
        sleep 30
    
    - name: Run contract tests
      run: |
        pytest tests/contract/ -v \
          --maxfail=3
    
    - name: Cleanup services
      if: always()
      run: |
        docker-compose -f docker-compose.test.yml down -v
    
    - name: Archive contract test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: contract-test-results
        path: tests/contract/reports/

  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r tests/requirements-test.txt
        pip install locust
    
    - name: Start services
      run: |
        docker-compose -f docker-compose.test.yml up -d
        sleep 30
    
    - name: Run performance tests
      run: |
        pytest tests/performance/ -v \
          --benchmark-only \
          --benchmark-json=benchmark.json
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results
        path: benchmark.json
    
    - name: Cleanup services
      if: always()
      run: |
        docker-compose -f docker-compose.test.yml down -v

  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install bandit safety semgrep
    
    - name: Run security scan with Bandit
      run: |
        bandit -r src/ -f json -o bandit-report.json || true
        bandit -r src/
    
    - name: Check dependencies with Safety
      run: |
        safety check --json --output safety-report.json || true
        safety check
    
    - name: Run Semgrep
      run: |
        semgrep --config=auto --json --output=semgrep-report.json src/ || true
    
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
          semgrep-report.json

  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install black flake8 mypy isort
    
    - name: Check code formatting with Black
      run: |
        black --check --diff src/ tests/
    
    - name: Check import sorting with isort
      run: |
        isort --check-only --diff src/ tests/
    
    - name: Lint with Flake8
      run: |
        flake8 src/ tests/ --format=junit-xml --output-file=flake8-report.xml
    
    - name: Type checking with MyPy
      run: |
        mypy src/ --junit-xml reports/mypy-report.xml || true
    
    - name: Upload quality reports
      uses: actions/upload-artifact@v3
      with:
        name: quality-reports
        path: |
          flake8-report.xml
          reports/

  build-test:
    name: Build Test
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, contract-tests]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build Docker images
      run: |
        docker build -t rag-system-api-gateway:test ./services/api-gateway
        docker build -t rag-system-document-service:test ./services/document-service
        docker build -t rag-system-embedding-service:test ./services/embedding-service
        docker build -t rag-system-retrieval-service:test ./services/retrieval-service
        docker build -t rag-system-generation-service:test ./services/generation-service
    
    - name: Test Docker images
      run: |
        # Test that images can start
        docker run --rm rag-system-api-gateway:test python -c "import fastapi; print('API Gateway OK')"
        docker run --rm rag-system-document-service:test python -c "import fastapi; print('Document Service OK')"
        docker run --rm rag-system-embedding-service:test python -c "import torch; print('Embedding Service OK')"

  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, contract-tests, build-test, code-quality]
    if: github.ref == 'refs/heads/develop'
    environment: staging
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Deploy to staging
      run: |
        echo "Deploying to staging environment..."
        # Add your staging deployment commands here
        # docker-compose -f docker-compose.staging.yml up -d
    
    - name: Run smoke tests
      run: |
        echo "Running smoke tests..."
        # Add smoke test commands here

  notify:
    name: Notify Results
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, contract-tests, security-tests, code-quality]
    if: always()
    
    steps:
    - name: Notify on success
      if: ${{ needs.unit-tests.result == 'success' && needs.integration-tests.result == 'success' && needs.contract-tests.result == 'success' }}
      run: |
        echo "✅ All tests passed successfully!"
    
    - name: Notify on failure
      if: ${{ needs.unit-tests.result == 'failure' || needs.integration-tests.result == 'failure' || needs.contract-tests.result == 'failure' }}
      run: |
        echo "❌ Some tests failed. Check the logs for details."
        exit 1
